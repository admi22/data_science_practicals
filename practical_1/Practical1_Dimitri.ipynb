{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "id1w7kwZVF3I"
   },
   "source": [
    "# Practical 1 : Implementation of Linear Regression (Ridge, Lasso)\n",
    "\n",
    "First part:\n",
    "- Implement linear regression model \n",
    "    - using least squares method\n",
    "    - implement directly using the NumPy package\n",
    "\n",
    "Second part:\n",
    "- regularization\n",
    "- polynomial basis expansion\n",
    "- cross validation\n",
    "- scikit-learn: https://scikit-learn.org/\n",
    "\n",
    "You will need to use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTZv9o5i4gy3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1-ZQWqTVPno"
   },
   "source": [
    "For the purpose of testing, we’ll use the winequality dataset. The dataset is available here:\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine+Quality In order to make it easier to import the dataset, we’ve converted the data to the numpy array format and shuffled it so that you can start the practical directly. The dataset is available on the course website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TzDL9RQiVaPY"
   },
   "source": [
    "The dataset has two files. We’ll focus on the white wine data, which is the larger dataset. You can load the data from the files as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1423,
     "status": "ok",
     "timestamp": 1596436129238,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "NYkwbebUVO_i",
    "outputId": "80ed8916-85c3-4564-cda8-d8a8f36aaa1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is a matrix with shape (4898, 11), which has 4898 records and 11 attributes.\n",
      "y is a vector with 4898 values, which stores the corresponding labels of the data records in X\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "# X is a matrix such that each row stores a data record \n",
    "# y is a vector of the corresponding labels of the records\n",
    "X, y = cp.load(open('winequality-white.pickle', 'rb'))\n",
    "\n",
    "# check the size of the data\n",
    "print(\"X is a matrix with shape {}, which has {} records and {} attributes.\".format(X.shape, X.shape[0], X.shape[1]))\n",
    "print(\"y is a vector with {} values, which stores the corresponding labels of the data records in X\".format(y.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGuNg0KbWN0z"
   },
   "source": [
    "In order to get consistent results, all students should use the same 80% of the data as training\n",
    "data. We’ll use the remaining as test data. To achieve this split run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1416,
     "status": "ok",
     "timestamp": 1596436129239,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "6ZqbBa8bWNYg",
    "outputId": "da274c4e-c3ed-4ac0-8442-27befcf26f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (3918, 11)\n",
      "Shape of y_train: (3918,)\n",
      "Shape of X_test: (980, 11)\n",
      "Shape of y_test: (980,)\n"
     ]
    }
   ],
   "source": [
    "# The function splits the dataset into the training dataset and the test dataset.\n",
    "# The parameter split_coeff is a percentage value such that\n",
    "# the first split_coeff of the dataset goes to the training dataset, \n",
    "# and the remaining data goes to the test dataset.\n",
    "def split_data(X, y, split_coeff):\n",
    "    N, _ = X.shape # get the number of records (rows)\n",
    "    train_size = int(split_coeff * N) # use the first split_coeff of the data as the training data\n",
    "    X_train = X[:train_size] # the first training_size records\n",
    "    y_train = y[:train_size]\n",
    "    X_test = X[train_size:] # the last test_size records\n",
    "    y_test = y[train_size:]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(X, y, 0.8) # use 80% of the data as training data\n",
    "\n",
    "# check the size of the splitted dataset\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RL1N8mKUWYnx"
   },
   "source": [
    "We’ll not touch the test data except for reporting the errors of our learned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2yKNR49Wkn8"
   },
   "source": [
    "## Understanding What We’re Predicting\n",
    "\n",
    "Before we get to training a linear model on the data and using it to make predictions, let’s look\n",
    "at the spread of y values on the training set. The values are integers between 3 and 9 indicating\n",
    "the quality of the wine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PMpsZNSWthB"
   },
   "source": [
    "### **Task 1**\n",
    "Make a bar chart showing the distribution of y values appearing in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1596436129240,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "4L_JDK3dWrsR",
    "outputId": "71b22bf6-77ce-4bd6-d5b1-61f633923144"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title\n",
    "# Task 1: \n",
    "# the function takes the training dataset as the input, and make the bar chart\n",
    "def plot_bar_chart_score(X_train, y_train):\n",
    "    plt.title(\"Distribution of Score of wines\") \n",
    "    px, py = np.unique(y_train, return_counts=True)\n",
    "    plt.xlabel(\"Score\") \n",
    "    plt.ylabel(\"number of wines\")\n",
    "    plt.xticks(px)\n",
    "    plt.bar(px,py) \n",
    "    plt.show()\n",
    "\n",
    "plot_bar_chart_score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxjlElni2FcH"
   },
   "source": [
    "### **Task 2** \n",
    "Implement the trivial predictor, which uses the average value of y on the training set as the prediction for ever datapoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1596436129240,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "-V3xFYexX1lt",
    "outputId": "5e57738e-87d5-408c-f1bf-9df66a175f35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of y on the training label values is 5.878764675855028\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "# Task 2: implement the simplest predictor\n",
    "# The function computes the average value of y on the training label values\n",
    "def compute_average(y_train):\n",
    "    return np.average(y_train)\n",
    "\n",
    "y_train_avg = compute_average(y_train)\n",
    "print(\"Average of y on the training label values is {}\".format(y_train_avg))\n",
    "\n",
    "# The simplest predictor returns the average value.\n",
    "def simplest_predictor(X_test, y_train_avg):\n",
    "  return y_train_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x531Q_SxXV14"
   },
   "source": [
    "### **Task 3**\n",
    "Report the mean squared error, i.e., the average of the squared residuals, using this simplest of predictors on the training and test data. We should hope that our models beat at lease this baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1596436129240,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "mV8l6Ci9YlgL",
    "outputId": "f57858dc-d0fc-40fe-dbf7-c652d2f8fddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplest Predictor\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.7768\n",
      "MSE (Testing)  = 0.8139\n"
     ]
    }
   ],
   "source": [
    "# We will evaluate our simplest predictor here. \n",
    "# Implement a function that can report the mean squared error \n",
    "# of a predictor on the given test data\n",
    "# Input: test dataset and predictor\n",
    "# Output: mean squared error of the predictor on the given test data\n",
    "def test_data(X_test, y_test, predictor: callable=None):\n",
    "    # Applies the predictor to each row to compute the predicted values\n",
    "    y_predicted = np.apply_along_axis(predictor, 1, X_test)\n",
    "\n",
    "    # TODO: compute the mean squared error of y_predicted\n",
    "    # The code below is just for compilation. \n",
    "    # You need to delete it and write your own code.\n",
    "    mse = np.average((y_test - y_predicted)**2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# use the above function test_data to evaluate the simplest predictor\n",
    "# we use the lambda function here to pass the function simplest_predictor to the evaluator.\n",
    "mse_simplest_predictor_train = test_data(X_train, y_train, lambda x: simplest_predictor(x, y_train_avg))\n",
    "mse_simplest_predictor_test = test_data(X_test, y_test, lambda x: simplest_predictor(x, y_train_avg))\n",
    "\n",
    "# Report the result\n",
    "print('Simplest Predictor')\n",
    "print('--------------------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_simplest_predictor_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_simplest_predictor_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geiyM1Nea0az"
   },
   "source": [
    "## Linear Model Using Least Squares\n",
    "\n",
    "Let us first fit a linear regression model and then calculate the training and test error. We’ll\n",
    "actually use the closed form solution of the least squares estimate for the linear model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRPPA6HMbNOr"
   },
   "source": [
    "### **Task 4**\n",
    "Is it strictly necessary to standardize the data for the linear model using the least squares method? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not needed, but if we do basis expansion with polynomial, as we later will, it is needed to keep the weights of Ridge and Laso un-biased. And since we want to compare the methodes afterwards, it helps to standadize them now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9he5QMmfqL3_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSEwFGp_bqAI"
   },
   "source": [
    "### **Task 5**\n",
    "Standardize the data, i.e., make the data for every feature have mean 0 and variance 1. \n",
    "\n",
    "We do the standardization using the training data, and we need to remember the means and\n",
    "the standard deviations so that they can be applied to the test data as well. Apply the\n",
    "standardization so that every feature in the training data has mean 0 and variance 1. Apply\n",
    "the same transformation to the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1596436129241,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "trjwkcgybhDH",
    "outputId": "d87a4635-354f-47e2-947a-e843f027e4cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_std: (3918, 11)\n",
      "Mean: [6.85427514e+00 2.78390761e-01 3.34892802e-01 6.42623788e+00\n",
      " 4.58213374e-02 3.53263144e+01 1.38513272e+02 9.94040729e-01\n",
      " 3.18647524e+00 4.89055641e-01 1.05115799e+01]\n",
      "Standard deviation: [8.39100902e-01 9.95630176e-02 1.24249975e-01 5.06377532e+00\n",
      " 2.16660282e-02 1.71004677e+01 4.23956179e+01 2.97972269e-03\n",
      " 1.49949475e-01 1.12992053e-01 1.22536544e+00]\n"
     ]
    }
   ],
   "source": [
    "# Input: training data\n",
    "# Output: standardize training data, standard deviations and means\n",
    "def standardize_data(X):\n",
    "    # TODO: compute mean, standard deviations and the standardized data\n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    mean = np.zeros(X.shape[1])\n",
    "    std = np.zeros(X.shape[1])\n",
    "    X_std = np.zeros(X.shape)\n",
    "    for i in range(0,X.shape[1]):\n",
    "        mean[i] = np.average(X[:,i])\n",
    "        std[i] = np.std(X[:,i])\n",
    "        X_std[:,i] = (X[:,i]-mean[i])/float(std[i])\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n",
    "    \n",
    "    return X_std, mean, std\n",
    "\n",
    "X_train_std, X_train_mean, X_train_std_div = standardize_data(X_train)\n",
    "print(\"X_train_std:\", X_train_std.shape)\n",
    "print(\"Mean:\", X_train_mean)\n",
    "print(\"Standard deviation:\", X_train_std_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1380,
     "status": "ok",
     "timestamp": 1596436129242,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "RjzbA5JpM759",
    "outputId": "ff594788-2fdd-419c-98fa-beac6a53cfc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 11)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Standardize the test data using the mean and standrad deviation you computed for the training data\n",
    "###################################################\n",
    "##### YOUR CODE STARTS HERE #######################\n",
    "###################################################\n",
    "X_test_std = (X_test - X_train_mean * np.ones((1,X_test.shape[1])) )/X_train_std_div\n",
    "print(X_test_std.shape)\n",
    "###################################################\n",
    "##### YOUR CODE ENDS HERE #########################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vT4_Sl42bxmD"
   },
   "source": [
    "### **Task 6**\n",
    "Implement the linear model predictor, and report the mean squared error using the linear model on the training and test data.\n",
    "\n",
    "We will do this in several steps. We need to implement the function for computing the parameters based on the training dataset. Note we need to add the bias column to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1374,
     "status": "ok",
     "timestamp": 1596436129242,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "A4JtLr6pdJV7",
    "outputId": "dfd57312-284f-4ce9-820b-4fdbdfbec8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: (12,)\n"
     ]
    }
   ],
   "source": [
    "# the function adds a column of ones to the front of the input matrix\n",
    "def expand_with_ones(X):\n",
    "    # TODO: adds a column of ones to the front of the input matrix\n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    n = X.shape[1]\n",
    "    X_out = np.ones((X.shape[0],n+1))\n",
    "    X_out[:,0:n] = X\n",
    "    return X_out\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n",
    "\n",
    "# The function computes the parameters\n",
    "def least_squares_compute_parameters(X_input, y):\n",
    "    # add the bias column to the dataset\n",
    "    X = expand_with_ones(X_input)\n",
    "    # TODO: compute the parameters based on the expanded X and y\n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    X_T = np.matrix.transpose(X)\n",
    "    return np.linalg.inv(X_T @ X ) @ X_T @ y\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n",
    "\n",
    "# train the linear model parameters\n",
    "\n",
    "#w = least_squares_compute_parameters(np.zeros((2,2)), np.matrix.transpose(np.ones(2))) \n",
    "w = least_squares_compute_parameters(X_train_std, y_train) \n",
    "print(\"w:\", w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lasj_1PpeZib"
   },
   "source": [
    "We then implement the linear model predictor given the dataset and the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lb-hNagxc3Wj"
   },
   "outputs": [],
   "source": [
    "# Implement the linear model predictor\n",
    "# Input: test data and parameters\n",
    "# Output: predicted values\n",
    "def linear_model_predictor(X, w):\n",
    "    # TODO: compute the predicted values based on the test dataset and the parameters\n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    return X @ w\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFOYpwbufz7J"
   },
   "source": [
    "We can now evaluate our linear model predictor on the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1596436129243,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "LuHHmn2RB55j",
    "outputId": "b6cb4556-2618-419a-a082-214f2e6ecb5e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6fe5d0a9e633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use the function test_data to evaluate the linear model predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmse_linear_model_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_with_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlinear_model_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean squared error is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_linear_model_predictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_std' is not defined"
     ]
    }
   ],
   "source": [
    "# use the function test_data to evaluate the linear model predictor\n",
    "mse_linear_model_predictor = test_data(expand_with_ones(X_test_std), y_test, lambda x: linear_model_predictor(x, w))\n",
    "print(\"Mean squared error is {}\".format(mse_linear_model_predictor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqj4HKAihF7Q"
   },
   "source": [
    "## Learning Curves\n",
    "\n",
    "Let us see if the linear model is overfitting or underfitting. Since the dataset is somewhat large and there are only 11 features, our guess should be that it may either be underfitting or be about right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDLCsjzWhMCp"
   },
   "source": [
    "Starting with 20 datapoints, we’ll use training datasets of increasing size, in increments of 20 up to about 600 datapoints. For each case train the linear model only using the first n elements of\n",
    "the training data. Calculate the training error (on the data used) and the test error (on the full test set). Plot the training error and test error as a function of the size of the dataset used for\n",
    "training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNf11kurCgKF"
   },
   "source": [
    "### **Task 7** \n",
    "Implement a function that evaluates the linear model over the training dataset with the input size.\n",
    "The function takes a dataset and the split coefficient as inputs, and\n",
    "1. splits the data to training and test datasets,\n",
    "2. standardizes the data,\n",
    "3. trains the linear model, and\n",
    "4. reports the mse of the linear model predictor on both training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1355,
     "status": "ok",
     "timestamp": 1596436129244,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "UcGRQBrEb106",
    "outputId": "179c5ec0-ee87-4c4b-a02b-d97d55862e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using Linear Models\n",
      "-----------------------\n",
      "\n",
      "MSE (Training) = 0.5640\n",
      "MSE (Testing)  = 0.5607\n"
     ]
    }
   ],
   "source": [
    "# Input: dataset and split coefficient\n",
    "# Output: mse of the linear model predictor on both the training and test datasets\n",
    "def train_and_test(X, y, split_coeff):\n",
    "    # TODO: implement the function \n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    # Hints: use the functions you have implemented\n",
    "    X = standardize_data(X)[0]\n",
    "    n = int(X.shape[0]*split_coeff)\n",
    "    X_i = X[0:n,:]\n",
    "    y_i = y[0:n]\n",
    "    X_test = X[n:,:]\n",
    "    y_test = y[n:]\n",
    "    w = least_squares_compute_parameters(X_i, y_i)\n",
    "    mse_train = test_data(expand_with_ones(X_i), y_i, lambda x: linear_model_predictor(x, w))\n",
    "    mse_test = test_data(expand_with_ones(X_test), y_test, lambda x: linear_model_predictor(x, w))\n",
    "    return mse_train, mse_test\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n",
    "\n",
    "mse_train, mse_test = train_and_test(X, y, 0.8)\n",
    "print('MSE using Linear Models')\n",
    "print('-----------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTJw_BrzhRwi"
   },
   "source": [
    "### **Task 8**\n",
    "Report the learning curves plot. Also, explain whether you think the model is underfitting or not and how much data you need before getting the optimal test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1747,
     "status": "ok",
     "timestamp": 1596436129644,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "jDsdh4T3hcIU",
    "outputId": "621c4890-1c55-4e9b-f28f-33d60907d8b9",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_train_v = []\n",
    "mse_test_v = []\n",
    "\n",
    "TRAINING_SIZE_MAX = 601\n",
    "TRAINING_SIZE_MIN = 20\n",
    "\n",
    "# compute the errors over datasets with different sizes\n",
    "for train_size in range(TRAINING_SIZE_MIN, TRAINING_SIZE_MAX, 20):\n",
    "    # TODO: compute the training error and test error on datasets with size train_size\n",
    "    # and add them to mse_train_v and mse_test_v, respectively\n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    mse_train, mse_test = train_and_test(X_train, y_train, float(train_size)/X_train.shape[0])\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n",
    "    mse_train_v.append(mse_train)\n",
    "    mse_test_v.append(mse_test)\n",
    "\n",
    "# The below code outputs the plot of mse from different training sizes\n",
    "plt.figure(2)\n",
    "plt.plot(np.arange(TRAINING_SIZE_MIN, TRAINING_SIZE_MAX, 20), mse_train_v, 'r--', label=\"Training Error\")\n",
    "plt.plot(np.arange(TRAINING_SIZE_MIN, TRAINING_SIZE_MAX, 20), mse_test_v, 'b-', label=\"Test Error\")\n",
    "plt.xlabel('Dataset Size')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9A9VqDTzOdfd"
   },
   "source": [
    "Since the test-data shows a low MSE after arround 100 datapoints and stais there, we can make the assumption that the methode is not over-fitting. The fact that the training error and the test error are almost the same supports this assumption. But an MSE of 0.7 for a standardized data-set is still quiet high, so it is probably underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djpsaTu_kK3T"
   },
   "source": [
    "## Polynomial Basis Expansion with Ridge and Lasso\n",
    "\n",
    "For this part use the following from the scikit-learn package. Read the documentation available here: http://scikit-learn.org/stable/modules/classes.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnw2FEvqkdV_"
   },
   "source": [
    "You will need the use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TM0nkNbkhfM"
   },
   "outputs": [],
   "source": [
    "# You will need the following libs. \n",
    "# Fell free to import other libs. \n",
    "\n",
    "# import the preprocessing libs for standarization and basis expansion\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures \n",
    "\n",
    "# Ridge and Lasso linear model\n",
    "from sklearn.linear_model import Ridge, Lasso \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fAfOfXCksT9"
   },
   "source": [
    "Try 5 powers of 10 for lambda from 10^-2 to 10^2 and use degree 2 basis expansion. Fit ridge and lasso using degree 2 polynomial expansion with these values of lambda. You should pick the optimal values for lambda using a validation set. Set the last 20% of the training set for the purpose of validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCwBPuOXlRF7"
   },
   "source": [
    "### **Task 9**\n",
    "Let's implement the function for expanding the basis of the dataset. \n",
    "\n",
    "Hints: use `PolynomialFeatures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50azFolql1qA"
   },
   "outputs": [],
   "source": [
    "def expand_basis(X, degree):\n",
    "    # TODO: expand the basis of X for the degree\n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    # Hints: use the function PolynomialFeatures\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    return poly.fit_transform(X)\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6jwkPevimQri"
   },
   "source": [
    "### **Task 10**\n",
    "Prepare the training, test and validation data using the expanded dataset. Expand and standardize the the data. \n",
    "\n",
    "Hints: you can use `StandardScaler` and `std_scaler` to standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQCq4G9YmW7w"
   },
   "outputs": [],
   "source": [
    "# TODO: the training, test and validation data using the expanded dataset.\n",
    "# The code below is just for compilation. \n",
    "# You need to replace it by your own code.\n",
    "def prepare_data(X, y, degree):\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    # Hints: follow the steps    \n",
    "    # You need to parpare four datasets:\n",
    "    # 1. training data -- X_train, y_train\n",
    "    # 2. test data -- X_test, y_test\n",
    "    # 3. validation data -- X_train_v, y_train_v\n",
    "    # 4. training data (cross validation) -- X_train_n, y_train_n\n",
    "    \n",
    "    # You need expand the basis of the data, and do standardization\n",
    "    X = expand_basis(X, degree)\n",
    "    \n",
    "    #normalizing\n",
    "    mean = np.zeros(X.shape[1])\n",
    "    std = np.zeros(X.shape[1])\n",
    "    X_std = np.zeros(X.shape)\n",
    "    for i in range(0,X.shape[1]):\n",
    "        mean[i] = np.average(X[:,i])\n",
    "        std[i] = np.std(X[:,i])\n",
    "        if(std[i] == 0): \n",
    "            X_std[:,i] = 1\n",
    "        else:\n",
    "            X_std[:,i] = (X[:,i]-mean[i])/float(std[i])\n",
    "    X = X_std\n",
    "    \n",
    "    mean_y = np.mean(y)\n",
    "    std_y = np.std(y)\n",
    "    \n",
    "    y = (y-mean_y)/float(std_y)\n",
    "    \n",
    "        \n",
    "        \n",
    "    splitter = int(X.shape[0]*0.8)\n",
    "\n",
    "    # training data\n",
    "    X_train = X[:splitter]\n",
    "    y_train = y[:splitter]\n",
    "\n",
    "    # test data\n",
    "    X_test = X[splitter:]\n",
    "    y_test = y[splitter:]\n",
    "\n",
    "\n",
    "    # further split the training data to training and validation data\n",
    "    # training data\n",
    "    splitter2 = int(X_train.shape[0]*0.8)\n",
    "    X_train_n = X_train[:splitter2] \n",
    "    y_train_n = y_train[:splitter2]\n",
    "\n",
    "    # validation data\n",
    "    X_train_v = X_train[splitter2:]\n",
    "    y_train_v = y_train[splitter2:]\n",
    "\n",
    "    return X_train, y_train, X_train_n, y_train_n, X_train_v, y_train_v, X_test, y_test\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n",
    "\n",
    "X_train, y_train, X_train_n, y_train_n, X_train_v, y_train_v, X_test, y_test = prepare_data(X, y, 2)# here we expand the dataset with degree 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3BxxtM3nghU"
   },
   "source": [
    "### **Task 11**\n",
    "We have prepared the training data and the validation data. We can now choose the hyper parameter lambda for Ridge and Lasso using the validation data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3266,
     "status": "ok",
     "timestamp": 1596436131187,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "SvXcAGW1oHq1",
    "outputId": "25a38d1f-013f-4b0a-9cbb-3f08b68c0371"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2394543390648, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.239287221947, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.239066302979, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2387742611564, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2383881991366, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2378778480124, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.237203194119, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2363113418257, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.235132366367, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2335738315691, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.231513542686, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2287899662266, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2251895657621, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.220430061039, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2141382982754, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2058209972835, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.194826083185, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.1802915732221, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.1610780150976, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.13567920499, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.1021040920095, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.0577208824004, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.9990508376924, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.9214958926718, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.8189787631972, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.6834675308348, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.5043478154903, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.2675938094002, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1001.9546743662414, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1001.5411105486183, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1000.9945725694122, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1000.2723769143134, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 999.3181935298235, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 998.0577205634128, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 996.3930197559955, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 994.1951366412551, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 991.29449598694, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 987.4683539678917, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 982.4250403113116, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 975.7836375652446, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 967.0484958967152, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 955.5784362725296, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 940.5498654695028, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 920.916642902947, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 895.3675403230023, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.2051116891735, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 821.1612452914305, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 770.0846775027192, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 707.2257625176343, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 630.462023426913, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 539.8388941716057, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 442.7485694369344, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 365.05081107485285, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 294.72887844736886, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 142.33074285937096, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.516824087086206, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.545507705975751, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.855173933696506, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.831351051095908, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9575335416348025, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4567524283013427, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.759132274226431, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1743650878056542, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7205671145688939, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5339277604252857, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5291713663700648, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4210769379883459, tolerance: 0.30911247512415996\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge lambda: 0.0001519911082952933\n",
      "Lasso lambda: 0.0002656087782946689\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The function takes the training and validation data as inputs, and \n",
    "# returns the lambda value that has the minimal mse\n",
    "# We use is_ridge to indicate the model we consider. \n",
    "# is_ridge = True indicates Ridge while is_ridge = False indicates Lasso\n",
    "def choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, is_ridge: bool, plot = True):\n",
    "    mse_arr = []\n",
    "    lam_arr = []\n",
    "    #for i in range(0,X_train_n.shape[1]):\n",
    "    #    print(np.average(X_train_n[:,i]))\n",
    "\n",
    "    # Try lambda values from 10^-2 to 10^2. \n",
    "    # Record the mse and the lambda values in mse_arr and lam_arr\n",
    "    # The code below is just for compilation. \n",
    "    # You need to replace it by your own code.\n",
    "    ###################################################\n",
    "    ##### YOUR CODE STARTS HERE #######################\n",
    "    ###################################################\n",
    "    for pow_lam in np.linspace(-10,2,100): #range(-, 2+1, 0.1):\n",
    "        lam = 10 ** pow_lam\n",
    "        w = \"\"\n",
    "        mse = \"\"\n",
    "        X = X_train_n\n",
    "        y = y_train_n\n",
    "        converged = True\n",
    "        if(is_ridge):\n",
    "            #w = np.linalg.inv(np.matrix.transpose(X)@X+lam*np.eye(X.shape[1]))@np.matrix.transpose(X)@y\n",
    "            ridge = Ridge(alpha = lam)\n",
    "            ridge.fit(X,y)\n",
    "            w = ridge.coef_\n",
    "        else:\n",
    "            try:\n",
    "                lasso = Lasso(alpha = lam)\n",
    "                lasso.fit(X,y)\n",
    "                w = lasso.coef_\n",
    "            except:\n",
    "                print(\"ignoring lasso with \", lam, \" because it doesn't converge\")\n",
    "                converged = False\n",
    "        if converged:\n",
    "            mse = test_data(X_train_v, y_train_v, lambda x: linear_model_predictor(x, w))\n",
    "            mse_arr.append(mse)\n",
    "            lam_arr.append(lam)\n",
    "    ###################################################\n",
    "    ##### YOUR CODE ENDS HERE #########################\n",
    "    ###################################################\n",
    "\n",
    "\n",
    "    # get the index of the lambda value that has the minimal use\n",
    "    lambda_idx_min = np.argmin(np.array(mse_arr))\n",
    "    # print(lam_arr[lambda_idx_min])\n",
    "\n",
    "    # plot of the lambda values and their mse\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.semilogx(lam_arr, mse_arr)\n",
    "\n",
    "    # return the best lambda value\n",
    "    return lam_arr[lambda_idx_min]\n",
    "\n",
    "# call the function to choose the lambda for Ridge and Lasso\n",
    "lam_ridge = choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, True)\n",
    "lam_lasso = choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, False)\n",
    "\n",
    "print(\"Ridge lambda:\", lam_ridge)\n",
    "print(\"Lasso lambda:\", lam_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAuX0uU5k9qD"
   },
   "source": [
    "### **Task 12**:\n",
    "Once you’ve obtained the optimal values for lambda for Ridge and Lasso, train these models using these hyperparameters on the full training data. Then report\n",
    "the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3259,
     "status": "ok",
     "timestamp": 1596436131187,
     "user": {
      "displayName": "Haozhe Zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhewCb1FImnjURCLugyfalL8wVXJomnuoEHUckN=s64",
      "userId": "15943369882491692800"
     },
     "user_tz": -480
    },
    "id": "VmwHESkg77zK",
    "outputId": "9bb9c1cf-1649-40e6-9162-2244525d9446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Ridge Regression with using degree 2 polynomial expansion and lambda = 0.0002\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.6320\n",
      "MSE (Testing)  = 0.6508\n",
      "\n",
      "\n",
      "For Lasso with using degree 2 polynomial expansion and lambda = 0.0003\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "MSE (Training) = 0.6479\n",
      "MSE (Testing)  = 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michi/data_science/data_science_env/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 269.08849856097527, tolerance: 0.3880936624362163\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "# TODO: train the Ridge and Lasso models using their best parameters, and\n",
    "#       report their mse\n",
    "###################################################\n",
    "##### YOUR CODE STARTS HERE #######################\n",
    "###################################################\n",
    "# Hints: train these models on the full training data \n",
    "ridge = Ridge(alpha = lam_ridge)\n",
    "ridge.fit(X_train,y_train)\n",
    "w_ridge = ridge.coef_\n",
    "lasso = Lasso(alpha = lam_lasso)\n",
    "lasso.fit(X_train,y_train)\n",
    "w_lasso = lasso.coef_\n",
    "mse_ridge_train = test_data(X_train, y_train, lambda x: linear_model_predictor(x, w_ridge))\n",
    "mse_ridge_test = test_data(X_test, y_test, lambda x: linear_model_predictor(x, w_ridge))\n",
    "mse_lasso_train = test_data(X_train, y_train, lambda x: linear_model_predictor(x, w_lasso))\n",
    "mse_lasso_test = test_data(X_test, y_test, lambda x: linear_model_predictor(x, w_lasso))\n",
    "###################################################\n",
    "##### YOUR CODE ENDS HERE #########################\n",
    "###################################################\n",
    "\n",
    "# Report the result\n",
    "print('For Ridge Regression with using degree %d polynomial expansion and lambda = %.4f' % (2, lam_ridge))\n",
    "print('--------------------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_ridge_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_ridge_test)\n",
    "\n",
    "print('\\n\\nFor Lasso with using degree %d polynomial expansion and lambda = %.4f' % (2, lam_lasso))\n",
    "print('---------------------------------------------------------------------\\n')\n",
    "print('MSE (Training) = %.4f' % mse_lasso_train)\n",
    "print('MSE (Testing)  = %.4f' % mse_lasso_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Os9tKKLd8gMU"
   },
   "source": [
    "## Larger Degrees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfqRAlv1PBXi"
   },
   "source": [
    "### **Task 13**\n",
    "Try using higher degree basis expansion. You may want to use k-fold cross validation to determine\n",
    "the values of hyperparameters rather than just keeping a validation set. \n",
    "\n",
    "Hints: Use `KFold` to do this automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpwY7UtQ8l-0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam ridge:  1e-10\n",
      "lam lasso:  1e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2394543390648, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.239287221947, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.239066302979, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2387742611564, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2383881991366, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2378778480124, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.237203194119, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2363113418257, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.235132366367, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2335738315691, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.231513542686, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2287899662266, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2251895657621, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.220430061039, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2141382982754, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.2058209972835, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.194826083185, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.1802915732221, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.1610780150976, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.13567920499, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.1021040920095, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003.0577208824004, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.9990508376924, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.9214958926718, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.8189787631972, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.6834675308348, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.5043478154903, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1002.2675938094002, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1001.9546743662413, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1001.5411105486183, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1000.9945725694123, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1000.2723769143136, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 999.3181935298236, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 998.0577205634127, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 996.3930197559954, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 994.1951366412551, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 991.2944959869404, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 987.468353967891, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 982.4250403113115, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 975.783637565244, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 967.0484958967153, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 955.578436272529, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 940.5498654695017, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 920.9166429029448, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 895.3675403229948, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.2051116891732, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 821.1612452914296, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 770.0846775027197, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 707.2257625176317, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 630.4620234269049, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 539.8388941716195, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 442.74856943691896, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 365.05081107485285, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 294.72887844736886, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 142.33074285938756, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.51682408708416, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.54550770597666, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.85517393369673, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.831351051095908, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9575335416348025, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4567524283013427, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.759132274226431, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1743650878056542, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7205671145688939, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5339277604252857, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5291713663700648, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4210769379883459, tolerance: 0.30911247512415996\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam ridge:  0.0001519911082952933\n",
      "lam lasso:  0.0002656087782946689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 269.0884985609805, tolerance: 0.3880936624362163\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6568168524935, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6567642810916, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6566947847879, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6566029147637, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6564814679912, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6563209224923, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6561086907714, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.655828133823, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6554572530591, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6549669704059, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6543188454082, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6534620619825, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6523294441477, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6508321890369, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6488529041679, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6462364030285, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6427775372237, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6382051109578, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6321606224445, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6241701301234, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.6136071914719, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.5996434633595, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.5811840794901, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.556781647895, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.5245225644011, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.4818773918801, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.4255019967372, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.3509740974009, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.2524486625389, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 923.1221972897105, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 922.9500022129332, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 922.7223461578819, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 922.4213641507823, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 922.0234143419997, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 921.4972428240878, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 920.8014839288983, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 919.8813896807334, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 918.6645145083983, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 917.0503776414956, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 914.9181964170065, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 912.0924662820495, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 908.3480733392225, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 903.2653745406992, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 896.3886963332785, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 887.398736976339, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 875.5230269718395, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 858.8854651790093, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 837.5678996751175, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 809.234269850388, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 776.1724852251059, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 718.1752443843233, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 620.6635500159771, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 567.4618476714984, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 388.1814078586392, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 437.26274713679584, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 368.1878771551609, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 291.3187309470478, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 88.03471624327858, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.51695846964458, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.661210461016708, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.57580721443901, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.551361003700094, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.420302125482749, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.9937332144627362, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2869844003341768, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2670610894629135, tolerance: 0.30911247512415996\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam ridge:  2.656087782946684\n",
      "lam lasso:  0.0002656087782946689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 436.7520269406325, tolerance: 0.3880936624362163\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.6583e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.18922e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=2.84586e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=3.76502e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=4.93079e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=6.41639e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=8.50595e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.1096e-16): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1519648344921, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1519199389865, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1518605897716, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.151782133608, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1516784191764, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1515413148171, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.151360070938, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.151120477776, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1508037492102, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1503850529729, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.14983156196, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1490998774952, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1481326272208, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1468539940023, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1451637118689, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1429292607737, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1399754751911, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1360707612046, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1309089826218, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1240854363477, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1150653565676, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.1031412877701, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.0873786540279, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.0665417767325, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.0389971315853, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 862.0025858892617, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861.9544541441117, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861.8908298872738, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861.8067304736596, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861.6955648168447, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861.5486224071602, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861.3544055260328, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 861.0977309515135, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 860.7586117528798, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 860.3101706900989, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 859.7175333972336, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 858.9343859343355, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 857.8995117908268, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 856.529187016129, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 854.7265573883526, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 852.3896597766284, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 849.282621502038, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 845.1558053595328, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 839.7112445182232, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 832.5695786199803, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 823.6800165576445, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 812.0065560787115, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 795.9552893490167, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 776.6626306610688, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 745.940985319261, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 712.9430669198491, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 680.9886672936307, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 627.0425773494453, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 499.0251212256311, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 383.82028478825634, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 266.89166104716753, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204.57594831872746, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81.65964092891522, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.14337862549155, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.013165713075068, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.93695958856756, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.382395678200965, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.7793348589236757, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7546965949165951, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.046781449324726, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5770806760485812, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.33383557920433304, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6395275912718716, tolerance: 0.30911247512415996\n",
      "  positive)\n",
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3833881326977462, tolerance: 0.30911247512415996\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam ridge:  10.722672220103254\n",
      "lam lasso:  0.0008111308307896872\n",
      "[0.7149674781407558, 0.6507906823581097, 0.6954306901342647, 0.7366126433707392]\n",
      "[0.7149674781660534, 0.6658752740036019, 0.6782830332990926, 0.688287506172046]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimi/.local/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.64431325933856, tolerance: 0.3880936624362163\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# TODO: Try using higher degree basis expansion. Find the degree that gives the minimal mse. \n",
    "###################################################\n",
    "##### YOUR CODE STARTS HERE #######################\n",
    "###################################################\n",
    "# Hints: use KFold\n",
    "mse_rid = []\n",
    "mse_las = []\n",
    "for k in range(1,5):\n",
    "    X_train, y_train, X_train_n, y_train_n, X_train_v, y_train_v, X_test, y_test = prepare_data(X, y, k)\n",
    "    \n",
    "    lam_ridge = choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, True, plot = False)\n",
    "    lam_lasso = choose_hyper_param(X_train_n, y_train_n, X_train_v, y_train_v, False, plot = False)\n",
    "    \n",
    "    print( \"lam ridge: \", lam_ridge)\n",
    "    print( \"lam lasso: \",lam_lasso)\n",
    "    \n",
    "    ridge = Ridge(alpha = lam_ridge)\n",
    "    ridge.fit(X_train,y_train)\n",
    "    w_ridge = ridge.coef_\n",
    "    lasso = Lasso(alpha = lam_lasso)\n",
    "    lasso.fit(X_train,y_train)\n",
    "    w_lasso = lasso.coef_\n",
    "    mse_ridge_test = test_data(X_test, y_test, lambda x: linear_model_predictor(x, w_ridge))\n",
    "    mse_lasso_test = test_data(X_test, y_test, lambda x: linear_model_predictor(x, w_lasso))\n",
    "    mse_rid.append(mse_ridge_test)\n",
    "    mse_las.append(mse_lasso_test)\n",
    "\n",
    "\n",
    "print(mse_rid)\n",
    "print(mse_las)\n",
    "\n",
    "# The below code outputs the plot of mse from different training sizes\n",
    "plt.figure(4)\n",
    "plt.plot(np.arange(1, 5), mse_rid, 'r--',marker='o', label=\"ridge\")\n",
    "plt.plot(np.arange(1, 5), mse_las, 'b-',marker='x', label=\"lasso\")\n",
    "plt.xlabel('degree of basis expansion')\n",
    "plt.ylabel('mse')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "###################################################\n",
    "##### YOUR CODE ENDS HERE #########################\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report:\n",
    "Since this was the first Practical, a lot of time was spent on getting acquainted with Numpy and Pyplotlib. In the beginning we implemented some code manually, before we found later that there are library-methods that do the same thing. In task 11 we found that for both ridge and lasso the minimizing lambda was also the smallest lambda in the proposed range. So we expanded the range to include smaller lambdas, and with this method we found interesting minima. This also led to some warnings from the Sklearn library, since Lasso didn't always converge in these small ranges. But the fact that it didn't converge didn't make the results useless, and it performed still better than with bigger lambdas. Both ridge and lasso with polynomial expansion performed worse than the linear model, which irritated us, and let us think that there is a mistake in our implementation. But we could not find any mistake, so for now we assume these results are correct. In task 13 we decided against the use of kfolds. Kfolds would be useful if we ran each polynomial expansion multiple times, but since the size of polynomial expansions grows exponentially, we were already struggling with the computing power for task 13. Using multiple runs with kfolds would probably have increased the precision of our findings, but would have been to much for our machines to handle. For the same reason we had to stop at a polynomial expansion of degree 4.\n",
    "In this task we learned the usefulness of graphs to determine the quality of a regression. We also learned how to use training, test and validation-data to automate the process of finding good values for our model.\n",
    "The programming in this task was mostly done by Dimitri Degkwitz, with help by everyone else. Want we want our implementation to look like, problems and decision were talked about with all Team members, and it is hard to make a distinction or to remember who is responsible for what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP96ktvsOI4PiuW52tcNLjx",
   "collapsed_sections": [],
   "name": "Practical1_starter.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
